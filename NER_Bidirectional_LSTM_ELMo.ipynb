{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER_Bidirectional LSTM-ELMo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mriyank/NamedEntityRecognition_LSTM_CNN/blob/main/NER_Bidirectional_LSTM_ELMo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAlk9tGDG32Y"
      },
      "source": [
        "# __Document Annotator using Deep Recurring Neural Networks__\n",
        "\n",
        "### Suyash Agarwal\n",
        "### Mriyank Singh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVfw_7T5HUMB"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-uIRWjlFzdC",
        "outputId": "7a5e2b4b-bcf3-4311-871c-07b1b3312c13"
      },
      "source": [
        "%tensorflow_version 1.15\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.15`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "kLJvYy0_H3o4",
        "outputId": "4fc53ead-7f5e-448a-9e03-c812791909ce"
      },
      "source": [
        "dataset = pd.read_csv(\"gdrive/MyDrive/NLPProj/ner_dataset.csv\", encoding=\"latin1\")\n",
        "dataset = dataset.drop(['POS'], axis=1)\n",
        "dataset = dataset.fillna(method=\"ffill\")\n",
        "dataset.head(15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>marched</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>through</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>London</td>\n",
              "      <td>B-geo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>to</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>protest</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>war</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>in</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Iraq</td>\n",
              "      <td>B-geo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>and</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>demand</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Sentence #           Word    Tag\n",
              "0   Sentence: 1      Thousands      O\n",
              "1   Sentence: 1             of      O\n",
              "2   Sentence: 1  demonstrators      O\n",
              "3   Sentence: 1           have      O\n",
              "4   Sentence: 1        marched      O\n",
              "5   Sentence: 1        through      O\n",
              "6   Sentence: 1         London  B-geo\n",
              "7   Sentence: 1             to      O\n",
              "8   Sentence: 1        protest      O\n",
              "9   Sentence: 1            the      O\n",
              "10  Sentence: 1            war      O\n",
              "11  Sentence: 1             in      O\n",
              "12  Sentence: 1           Iraq  B-geo\n",
              "13  Sentence: 1            and      O\n",
              "14  Sentence: 1         demand      O"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i79Aojf8Lf4z",
        "outputId": "ac48527b-16e7-498f-cf74-e9934a913607"
      },
      "source": [
        "words = set(list(dataset['Word'].values))\n",
        "n_words = len(words)\n",
        "n_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35178"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4A06tDBSL4H0",
        "outputId": "34b3af63-c5e2-4edc-b06f-a5e877f214ac"
      },
      "source": [
        "tags = list(set(dataset[\"Tag\"].values))\n",
        "n_tags = len(tags)\n",
        "n_tags"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfxIVIRGMj0U"
      },
      "source": [
        "class SentenceExtractor(object):\n",
        "    \n",
        "    def __init__(self, data):\n",
        "        self.n_sent = 1\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"Word\"].values.tolist(),s[\"Tag\"].values.tolist())]\n",
        "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "    \n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmjiQrFEM9fC",
        "outputId": "24722c1d-d238-4607-80b1-657347e30e1d"
      },
      "source": [
        "extractor = SentenceExtractor(dataset)\n",
        "sen = extractor.get_next()\n",
        "sen = extractor.get_next()\n",
        "print(sen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Families', 'O'), ('of', 'O'), ('soldiers', 'O'), ('killed', 'O'), ('in', 'O'), ('the', 'O'), ('conflict', 'O'), ('joined', 'O'), ('the', 'O'), ('protesters', 'O'), ('who', 'O'), ('carried', 'O'), ('banners', 'O'), ('with', 'O'), ('such', 'O'), ('slogans', 'O'), ('as', 'O'), ('\"', 'O'), ('Bush', 'B-per'), ('Number', 'O'), ('One', 'O'), ('Terrorist', 'O'), ('\"', 'O'), ('and', 'O'), ('\"', 'O'), ('Stop', 'O'), ('the', 'O'), ('Bombings', 'O'), ('.', 'O'), ('\"', 'O')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4ZoKM2gNZRf",
        "outputId": "71345e01-4f1f-4bca-ec75-a24f3fc03eba"
      },
      "source": [
        "total_sen = extractor.sentences\n",
        "print(len(total_sen))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47959\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5HzlQoUOEeU",
        "outputId": "5c52ee12-3ef5-40a2-9363-572993615082"
      },
      "source": [
        "words2index = {w:i for i,w in enumerate(words)}\n",
        "tags2index = {t:i for i,t in enumerate(tags)}\n",
        "print(words2index['Israeli'])\n",
        "print(tags2index['B-gpe'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33263\n",
            "15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9knapzpdOOx3",
        "outputId": "b8b1e624-f020-4887-9265-f80d04a8ce38"
      },
      "source": [
        "max_len = 50\n",
        "X = [[w[0]for w in s] for s in total_sen]\n",
        "new_X = []\n",
        "for seq in X:\n",
        "    new_seq = []\n",
        "    for i in range(max_len):\n",
        "        try:\n",
        "            new_seq.append(seq[i])\n",
        "        except:\n",
        "            new_seq.append(\"PADword\")\n",
        "    new_X.append(new_seq)\n",
        "new_X[15]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Israeli',\n",
              " 'officials',\n",
              " 'say',\n",
              " 'Prime',\n",
              " 'Minister',\n",
              " 'Ariel',\n",
              " 'Sharon',\n",
              " 'will',\n",
              " 'undergo',\n",
              " 'a',\n",
              " 'medical',\n",
              " 'procedure',\n",
              " 'Thursday',\n",
              " 'to',\n",
              " 'close',\n",
              " 'a',\n",
              " 'tiny',\n",
              " 'hole',\n",
              " 'in',\n",
              " 'his',\n",
              " 'heart',\n",
              " 'discovered',\n",
              " 'during',\n",
              " 'treatment',\n",
              " 'for',\n",
              " 'a',\n",
              " 'minor',\n",
              " 'stroke',\n",
              " 'suffered',\n",
              " 'last',\n",
              " 'month',\n",
              " '.',\n",
              " 'PADword',\n",
              " 'PADword',\n",
              " 'PADword',\n",
              " 'PADword',\n",
              " 'PADword',\n",
              " 'PADword',\n",
              " 'PADword',\n",
              " 'PADword',\n",
              " 'PADword',\n",
              " 'PADword',\n",
              " 'PADword',\n",
              " 'PADword',\n",
              " 'PADword',\n",
              " 'PADword',\n",
              " 'PADword',\n",
              " 'PADword',\n",
              " 'PADword',\n",
              " 'PADword']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvZn7-F7OfBI",
        "outputId": "978a649c-feba-435c-e31e-f86f94dfbf1b"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "y = [[tags2index[w[1]] for w in s] for s in total_sen]\n",
        "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tags2index[\"O\"])\n",
        "y[15]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([15,  7,  7,  4, 16, 16, 16,  7,  7,  7,  7,  7, 12,  7,  7,  7,  7,\n",
              "        7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
              "        7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n37J1FYQixTk"
      },
      "source": [
        "batch_size=32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3jE8ktzO8Cq"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(new_X, y, test_size=0.15, random_state=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSwvWvsyRXtZ"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import add\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Lambda\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import backend as K\n",
        "sess = tf.Session()\n",
        "K.set_session(sess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDBXuLf9e2Hn"
      },
      "source": [
        "elmo_model = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=False)\n",
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(tf.tables_initializer())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-wjVWGQQ7K2"
      },
      "source": [
        "def ElmoEmbedding(x):\n",
        "    return elmo_model(inputs={\n",
        "                            \"tokens\": tf.squeeze(tf.cast(x, tf.string)),\n",
        "                            \"sequence_len\": tf.constant(batch_size*[max_len])\n",
        "                      },\n",
        "                      signature=\"tokens\",\n",
        "                      as_dict=True)[\"elmo\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfKoyuKYRwnp",
        "outputId": "8bee0947-71c9-4df0-f7cb-0fbbbaf54962"
      },
      "source": [
        "input_text = Input(shape=(max_len,), dtype=tf.string)\n",
        "embedding = Lambda(ElmoEmbedding, output_shape=(max_len, 1024))(input_text)\n",
        "x = Bidirectional(LSTM(units=512, return_sequences=True,\n",
        "                       recurrent_dropout=0.2, dropout=0.2))(embedding)\n",
        "x_rnn = Bidirectional(LSTM(units=512, return_sequences=True,\n",
        "                           recurrent_dropout=0.2, dropout=0.2))(x)\n",
        "x = add([x, x_rnn])\n",
        "out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH3Pd6EIU5IM",
        "outputId": "16c9ca5b-9c39-44e2-f90c-800c3c01c962"
      },
      "source": [
        "model = Model(input_text, out)\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (32, None, 1024)     0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (32, None, 1024)     6295552     lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (32, None, 1024)     6295552     bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (32, None, 1024)     0           bidirectional[0][0]              \n",
            "                                                                 bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 17)     17425       add[0][0]                        \n",
            "==================================================================================================\n",
            "Total params: 12,608,529\n",
            "Trainable params: 12,608,529\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4_4q9amgjaK"
      },
      "source": [
        "X_train, X_val = X_train[:1213*batch_size], X_train[-135*batch_size:]\n",
        "y_train, y_val = y_train[:1213*batch_size], y_train[-135*batch_size:]\n",
        "y_train = y_train.reshape(y_train.shape[0], y_train.shape[1], 1)\n",
        "y_val = y_val.reshape(y_val.shape[0], y_val.shape[1], 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktU9ogh2gyQG",
        "outputId": "2eb9d974-a8ee-4b6d-8c54-787c3972326a"
      },
      "source": [
        "history = model.fit(np.array(X_train), y_train, validation_data=(np.array(X_val), y_val),\n",
        "                    batch_size=batch_size, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 38816 samples, validate on 4320 samples\n",
            "Epoch 1/5\n",
            "38816/38816 [==============================] - 1536s 40ms/sample - loss: 0.0617 - acc: 0.9820 - val_loss: 0.0403 - val_acc: 0.9869\n",
            "Epoch 2/5\n",
            "38816/38816 [==============================] - 1532s 39ms/sample - loss: 0.0404 - acc: 0.9870 - val_loss: 0.0349 - val_acc: 0.9883\n",
            "Epoch 3/5\n",
            "38816/38816 [==============================] - 1532s 39ms/sample - loss: 0.0336 - acc: 0.9886 - val_loss: 0.0320 - val_acc: 0.9894\n",
            "Epoch 4/5\n",
            "38816/38816 [==============================] - 1528s 39ms/sample - loss: 0.0279 - acc: 0.9903 - val_loss: 0.0294 - val_acc: 0.9906\n",
            "Epoch 5/5\n",
            "38816/38816 [==============================] - 1528s 39ms/sample - loss: 0.0228 - acc: 0.9920 - val_loss: 0.0280 - val_acc: 0.9917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRFI0AiwUHCG"
      },
      "source": [
        "model.save(\"ELMO_trained_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8tAf0DeUOY7",
        "outputId": "d937c726-0b92-48e4-ed0a-bfd8c97455cd"
      },
      "source": [
        "X_test = X_test[:149*batch_size]\n",
        "test_pred = model.predict(np.array(X_test), verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4768/4768 [==============================] - 121s 25ms/sample\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oxK75LMVqxE",
        "outputId": "085702a8-998e-4587-93e9-f0ec93abcf06"
      },
      "source": [
        "!pip install seqeval\n",
        "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "idx2tag = {i: w for w, i in tags2index.items()}\n",
        "\n",
        "def pred2label(pred):\n",
        "    out = []\n",
        "    for pred_i in pred:\n",
        "        out_i = []\n",
        "        for p in pred_i:\n",
        "            p_i = np.argmax(p)\n",
        "            out_i.append(idx2tag[p_i].replace(\"PADword\", \"O\"))\n",
        "        out.append(out_i)\n",
        "    return out\n",
        "\n",
        "def test2label(pred):\n",
        "    out = []\n",
        "    for pred_i in pred:\n",
        "        out_i = []\n",
        "        for p in pred_i:\n",
        "            out_i.append(idx2tag[p].replace(\"PADword\", \"O\"))\n",
        "        out.append(out_i)\n",
        "    return out\n",
        "    \n",
        "pred_labels = pred2label(test_pred)\n",
        "test_labels = test2label(y_test[:149*32])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[?25l\r\u001b[K     |███████▌                        | 10 kB 22.4 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20 kB 21.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 30 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 40 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 43 kB 1.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=d134efec32544d0278e002899df362163114b064719bfa5a1bce3b4072a69e78\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ko_YsNGXWaBo",
        "outputId": "b07852aa-1140-4eb1-f79c-6c05b630dbe5"
      },
      "source": [
        "print(classification_report(test_labels, pred_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.38      0.18      0.25        49\n",
            "         eve       0.50      0.35      0.42        31\n",
            "         geo       0.87      0.86      0.86      3761\n",
            "         gpe       0.96      0.93      0.95      1534\n",
            "         nat       0.38      0.35      0.36        23\n",
            "         org       0.65      0.70      0.68      1929\n",
            "         per       0.75      0.79      0.77      1716\n",
            "         tim       0.84      0.86      0.85      2099\n",
            "\n",
            "   micro avg       0.81      0.83      0.82     11142\n",
            "   macro avg       0.67      0.63      0.64     11142\n",
            "weighted avg       0.82      0.83      0.82     11142\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKmOK3JTWlwd",
        "outputId": "1634ca2e-43a0-48c7-ab7e-1529f115cecd"
      },
      "source": [
        "i = 390\n",
        "p = model.predict(np.array(X_test[i:i+batch_size]))[0]\n",
        "p = np.argmax(p, axis=-1)\n",
        "print(\"{:15} {:5}: ({})\".format(\"Word\", \"Pred\", \"True\"))\n",
        "print(\"=\"*30)\n",
        "for w, true, pred in zip(X_test[i], y_test[i], p):\n",
        "    if w != \"PADword\":\n",
        "        print(\"{:15}:{:5} ({})\".format(w, tags[pred], tags[true]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word            Pred : (True)\n",
            "==============================\n",
            "Diplomats      :O     (O)\n",
            "at             :O     (O)\n",
            "the            :O     (O)\n",
            "U.N.           :B-geo (B-geo)\n",
            "nuclear        :O     (O)\n",
            "agency         :O     (O)\n",
            "say            :O     (O)\n",
            "the            :O     (O)\n",
            "United         :B-geo (B-geo)\n",
            "States         :I-geo (I-geo)\n",
            "and            :O     (O)\n",
            "its            :O     (O)\n",
            "European       :O     (O)\n",
            "allies         :O     (O)\n",
            "have           :O     (O)\n",
            "agreed         :O     (O)\n",
            "to             :O     (O)\n",
            "suspend        :O     (O)\n",
            "their          :O     (O)\n",
            "push           :O     (O)\n",
            "to             :O     (O)\n",
            "refer          :O     (O)\n",
            "Iran           :B-geo (B-geo)\n",
            "to             :O     (O)\n",
            "the            :O     (O)\n",
            "Security       :B-org (B-org)\n",
            "Council        :I-org (I-org)\n",
            "for            :O     (O)\n",
            "possible       :O     (O)\n",
            "sanctions      :O     (O)\n",
            "over           :O     (O)\n",
            "its            :O     (O)\n",
            "nuclear        :O     (O)\n",
            "activities     :O     (O)\n",
            ".              :O     (O)\n"
          ]
        }
      ]
    }
  ]
}